{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Original dataset, no oversampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/gianghoang/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/gianghoang/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import StratifiedKFold, KFold\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "import numpy as np\n",
    "import statistics\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.svm import SVC\n",
    "import preprocessor as pre\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import re\n",
    "import string\n",
    "import nltk\n",
    "nltk.download(\"stopwords\")\n",
    "nltk.download(\"wordnet\")\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.tokenize import word_tokenize\n",
    "from scipy import sparse\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv(\"Train.csv\", sep=',', encoding=\"utf-8\")\n",
    "test_data = pd.read_csv(\"Test.csv\", sep=',', encoding=\"utf-8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_raw = [x[0] for x in train_data[['text']].values]\n",
    "Y_train = [x[0] for x in train_data[['sentiment']].values]\n",
    "\n",
    "X_test_raw = [x[0] for x in test_data[['text']].values]\n",
    "X_test_ID = [x[0] for x in test_data[['id']].values]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train = np.array(Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_vectorizer = TfidfVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " if i didnt have you i'd never see the sun. #mtvstars lady gaga\t\n",
      " happy birthday to my dude @samshoe1! jason aldean bout to be live come the 5th\t\n"
     ]
    }
   ],
   "source": [
    "print(X_train_raw[5]) # has hashtag\n",
    "print(X_train_raw[34]) # has '!'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "english_stopwords = stopwords.words('english') + [\"'d\"]\n",
    "negated_token = 'negation'\n",
    "negation_stopwords = ['not', 'ain', \"should've\", \"could've\", 'shouldve', 'couldve', 'aren',\"aren't\",\n",
    " 'couldn',\n",
    " \"couldn't\",\n",
    " 'didn',\n",
    " \"didn't\",\n",
    " 'doesn',\n",
    " \"doesn't\",\n",
    " 'hadn',\n",
    " \"hadn't\",\n",
    " 'hasn',\n",
    " \"hasn't\",\n",
    " 'haven',\n",
    " \"haven't\",\n",
    " 'isn',\n",
    " \"isn't\",\n",
    " 'mightn',\n",
    " \"mightn't\",\n",
    " 'mustn',\n",
    " \"mustn't\",\n",
    " 'needn',\n",
    " \"needn't\",\n",
    " 'shan',\n",
    " \"shan't\",\n",
    " 'shouldn',\n",
    " \"shouldn't\",\n",
    " 'wasn',\n",
    " \"wasn't\",\n",
    " 'weren',\n",
    " \"weren't\",\n",
    " 'won',\n",
    " \"won't\",\n",
    " 'wouldn',\n",
    " \"wouldn't\", \n",
    " 'don',\n",
    " \"don't\"]\n",
    "neutral_stopwords = [word for word in english_stopwords if word not in negation_stopwords]\n",
    "no_apostrophe_stopwords = [re.sub(r'\\'', '', str(word)) for word in negation_stopwords]\n",
    "contrast_language = ['but', 'yet', 'however', 'despite', 'although', 'though', 'contrast']\n",
    "contrast_token = 'contrast'\n",
    "\n",
    "def process_tweet(tweet):\n",
    "    stemmer = PorterStemmer()\n",
    "    \n",
    "    tweet = tweet.lower() # lowercase everything\n",
    "    \n",
    "    #removing hyperlinks\n",
    "    tweet = re.sub(r'(http|https)?:\\/\\/(\\S+)', '', str(tweet))\n",
    "    \n",
    "    tweet = re.sub(r'#', '', str(tweet)) \n",
    "    #remove hashtags\n",
    "    \n",
    "    #removing usernames\n",
    "    tweet = re.sub(r'/(?<!\\w)@[\\w+]{1,15}\\b/', '', str(tweet))\n",
    "    \n",
    "    #removing numbers\n",
    "    tweet = re.sub(r'[0-9]+', '', str(tweet))\n",
    "    \n",
    "    #substitute common abbreviation\n",
    "    tweet = re.sub(r'wtf', \"what the fuck\", str(tweet))\n",
    "    tweet = re.sub(r'wth', \"what the hell\", str(tweet))\n",
    "    tweet = re.sub(r'rofl', \"rolling on floor laughing\", str(tweet))\n",
    "    tweet = re.sub(r'stfu', \"shut the fuck up\", str(tweet))\n",
    "    tweet = re.sub(r'btw', \"by the way\", str(tweet))\n",
    "    tweet = re.sub(r'lol', \"laugh out loud\", str(tweet))\n",
    "    tweet = re.sub(r'hmu', \"hit me up\", str(tweet))\n",
    "    tweet = re.sub(r'imo', \"in my opinion\", str(tweet))\n",
    "    tweet = re.sub(r'idk', \"I don't know\", str(tweet))\n",
    "    tweet = re.sub(r'idc', \"I don't care\", str(tweet))\n",
    "    tweet = re.sub(r'icymi', \"in case you missed it\", str(tweet))\n",
    "    tweet = re.sub(r'lmk', \"let me know\", str(tweet))\n",
    "    tweet = re.sub(r'nvm', \"nevermind\", str(tweet))\n",
    "    tweet = re.sub(r'tbh', \"to be honest\", str(tweet))\n",
    "    tweet = re.sub(r'tbf', \"to be frank\", str(tweet))\n",
    "    tweet = re.sub(r'lmao', \"laughing my ass off\", str(tweet))\n",
    "    tweet = re.sub(r'lmfao', \"laughing my fucking ass off\", str(tweet))\n",
    "    tweet = re.sub(r'smh', \"shaking my head\", str(tweet))\n",
    "    \n",
    "    #remove repeating characters\n",
    "    tweet = re.sub(r'(.)1+', r'1', str(tweet))\n",
    "    \n",
    "    #remove non-English characters\n",
    "    tweet = re.sub(\"[^a-zA-Z0-9\\s]+\", \" \",str(tweet))\n",
    "        \n",
    "#     tweet_tokenizer = TweetTokenizer(preserve_case=False, strip_handles=True,\n",
    "#                                reduce_len=True)\n",
    "    \n",
    "#     tokens = tweet_tokenizer.tokenize(tweet)\n",
    "    tokens = word_tokenize(tweet)\n",
    "    processed_tweet = []\n",
    "    \n",
    "    for token in tokens:\n",
    "        if len(token) <= 2:\n",
    "            continue\n",
    "        if token in negation_stopwords or token in no_apostrophe_stopwords:\n",
    "            processed_tweet.append(negated_token)\n",
    "        elif token in contrast_language:\n",
    "            processed_tweet.append(contrast_token)\n",
    "        elif (token not in neutral_stopwords and  # remove stopwords\n",
    "                token not in string.punctuation):  # remove punctuation\n",
    "            stemmed_token = stemmer.stem(token)  # stemming word\n",
    "            processed_tweet.append(stemmed_token)\n",
    "    return \" \".join(processed_tweet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_processed = [process_tweet(tweet) for tweet in X_train_raw]\n",
    "X_test_processed = [process_tweet(tweet) for tweet in X_test_raw]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_zero_R(tweet):\n",
    "    return Counter(Y_train).most_common(1)[0][0]\n",
    "Zero_R_predict = [predict_zero_R(tweet) for tweet in X_test_processed]\n",
    "\n",
    "# Zero-R baseline\n",
    "df = pd.DataFrame(columns = [\"id\", \"sentiment\"])\n",
    "for i in range(len(X_test_ID)):\n",
    "    new_row = {\"id\": X_test_ID[i], \"sentiment\": Zero_R_predict[i]}\n",
    "    df = df.append(new_row, ignore_index = True)\n",
    "df.to_csv('prediction.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_tfidf = tfidf_vectorizer.fit_transform(X_train_processed)\n",
    "\n",
    "#Use the feature set (vocabulary) from Train to vectorise the Test dataset \n",
    "X_test_tfidf = tfidf_vectorizer.transform(X_test_processed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_train_tfidf, Y_train, test_size = 0.20, shuffle = True, random_state = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "param_grid_SVC = {'C': [0.01, 0.1, 1, 10, 100],\n",
    "              'gamma': [1, 0.1, 0.01, 0.001, 0.0001],\n",
    "              'kernel': ['rbf', 'linear']}\n",
    " \n",
    "grid_SVC = GridSearchCV(SVC(), param_grid_SVC, refit = True, verbose = 3)\n",
    " \n",
    "# fitting the model for grid search\n",
    "grid_SVC.fit(X_train, y_train)\n",
    "pred_SVC = grid_SVC.predict(X_test)\n",
    " \n",
    "# print classification report\n",
    "print(classification_report(y_test, pred_SVC))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "print(grid_SVC.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "param_grid_LR = {'C': [0.01, 0.1, 1, 10, 100],\n",
    "              'penalty': ['l2'],\n",
    "              'solver': ['newton-cg', 'lbfgs', 'liblinear'],\n",
    "                'max_iter':[10000]}\n",
    " \n",
    "grid_LR = GridSearchCV(LogisticRegression(), param_grid_LR, refit = True, verbose = 3)\n",
    " \n",
    "# fitting the model for grid search\n",
    "grid_LR.fit(X_train, y_train)\n",
    "pred_LR = grid_LR.predict(X_test)\n",
    " \n",
    "# print classification report\n",
    "print(classification_report(y_test, pred_LR))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "print(grid_LR.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Multinomial\n",
    "MNBmodel = MultinomialNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Support Vector Machine model\n",
    "SVCmodel = SVC(C = 1.0, gamma = 1.0, kernel = 'linear', cache_size = 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Logistic Regression model\n",
    "LRmodel = LogisticRegression(C = 1.0, multi_class='multinomial', solver='newton-cg', max_iter = 10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "List of possible accuracy: [0.6290692342961944, 0.609353507565337, 0.6128440366972477, 0.5876146788990826, 0.5912844036697248, 0.615137614678899, 0.6059633027522936, 0.6357798165137615, 0.6385321100917432, 0.6123853211009175]\n",
      "\n",
      "Maximum Accuracy That can be obtained from this model is: 63.853211009174316 %\n",
      "\n",
      "Minimum Accuracy: 58.76146788990826 %\n",
      "\n",
      "Overall Accuracy: 61.37964026265201 %\n",
      "\n",
      "Overall Neg Pre: 51.276759197622944 %\n",
      "\n",
      "Overall Neg Rec: 31.29086731462848 %\n",
      "\n",
      "Overall Neg F1: 38.40200099927461 %\n",
      "\n",
      "Overall Neu Pre: 64.42926607573393 %\n",
      "\n",
      "Overall Neu Rec: 79.23350362629749 %\n",
      "\n",
      "Overall Neg F1: 70.81119288825431 %\n",
      "\n",
      "Overall Pos Pre: 56.25845200244937 %\n",
      "\n",
      "Overall pos Rec: 41.41576303705072 %\n",
      "\n",
      "Overall pos F1: 47.23443111266597 %\n"
     ]
    }
   ],
   "source": [
    "#K-fold MNB\n",
    "scaler = preprocessing.MaxAbsScaler()\n",
    "x_scaled = scaler.fit_transform(X_train_tfidf)\n",
    "\n",
    "skf = KFold(n_splits=10)\n",
    "lst_accu_stratified = []\n",
    "neg_pre = []\n",
    "neg_re = []\n",
    "neg_F1 = []\n",
    "neu_pre = []\n",
    "neu_re = []\n",
    "neu_F1 = []\n",
    "pos_pre = []\n",
    "pos_re = []\n",
    "pos_F1 = []\n",
    "  \n",
    "for train_index, test_index in skf.split(X_train_tfidf, Y_train):\n",
    "    x_train_fold, x_test_fold = x_scaled[train_index], x_scaled[test_index]\n",
    "    y_train_fold, y_test_fold = Y_train[train_index], Y_train[test_index]\n",
    "\n",
    "    MNBmodel.fit(x_train_fold, y_train_fold)\n",
    "    pred = MNBmodel.predict(x_test_fold)\n",
    "    lst_accu_stratified.append(MNBmodel.score(x_test_fold, y_test_fold))\n",
    "\n",
    "    matrix = classification_report(y_test_fold, pred, output_dict = True)\n",
    "    neg_pre.append(matrix['negative']['precision'])\n",
    "    neg_re.append(matrix['negative']['recall'])\n",
    "    neg_F1.append(matrix['negative']['f1-score'])\n",
    "    neu_pre.append(matrix['neutral']['precision'])\n",
    "    neu_re.append(matrix['neutral']['recall'])\n",
    "    neu_F1.append(matrix['neutral']['f1-score'])\n",
    "    pos_pre.append(matrix['positive']['precision'])\n",
    "    pos_re.append(matrix['positive']['recall'])\n",
    "    pos_F1.append(matrix['positive']['f1-score'])\n",
    "    \n",
    "print('List of possible accuracy:', lst_accu_stratified)\n",
    "print('\\nMaximum Accuracy That can be obtained from this model is:',\n",
    "      max(lst_accu_stratified)*100, '%')\n",
    "print('\\nMinimum Accuracy:',\n",
    "      min(lst_accu_stratified)*100, '%')\n",
    "print('\\nOverall Accuracy:',\n",
    "      np.mean(lst_accu_stratified)*100, '%')\n",
    "print('\\nOverall Neg Pre:',\n",
    "      np.mean(neg_pre)*100, '%')\n",
    "print('\\nOverall Neg Rec:',\n",
    "      np.mean(neg_re)*100, '%')\n",
    "print('\\nOverall Neg F1:',\n",
    "      np.mean(neg_F1)*100, '%')\n",
    "print('\\nOverall Neu Pre:',\n",
    "      np.mean(neu_pre)*100, '%')\n",
    "print('\\nOverall Neu Rec:',\n",
    "      np.mean(neu_re)*100, '%')\n",
    "print('\\nOverall Neg F1:',\n",
    "      np.mean(neu_F1)*100, '%')\n",
    "print('\\nOverall Pos Pre:',\n",
    "      np.mean(pos_pre)*100, '%')\n",
    "print('\\nOverall pos Rec:',\n",
    "      np.mean(pos_re)*100, '%')\n",
    "print('\\nOverall pos F1:',\n",
    "      np.mean(pos_F1)*100, '%')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "List of possible accuracy: [0.6703347088491518, 0.6570380559376433, 0.6509174311926605, 0.6513761467889908, 0.6431192660550459, 0.653211009174312, 0.6568807339449542, 0.6692660550458716, 0.6646788990825688, 0.6463302752293578]\n",
      "\n",
      "Maximum Accuracy That can be obtained from this model is: 67.03347088491518 %\n",
      "\n",
      "Minimum Accuracy: 64.31192660550458 %\n",
      "\n",
      "Overall Accuracy: 65.63152581300557 %\n",
      "\n",
      "Overall Neg Pre: 58.27485969194143 %\n",
      "\n",
      "Overall Neg Rec: 33.64247622896948 %\n",
      "\n",
      "Overall Neg F1: 42.1713117770657 %\n",
      "\n",
      "Overall Neu Pre: 67.15128203982823 %\n",
      "\n",
      "Overall Neu Rec: 83.91195884481618 %\n",
      "\n",
      "Overall Neg F1: 74.35030482786199 %\n",
      "\n",
      "Overall Pos Pre: 64.54025945817669 %\n",
      "\n",
      "Overall pos Rec: 46.04310032206516 %\n",
      "\n",
      "Overall pos F1: 53.24585212013909 %\n"
     ]
    }
   ],
   "source": [
    "skf = KFold(n_splits=10)\n",
    "lst_accu_stratified = []\n",
    "neg_pre = []\n",
    "neg_re = []\n",
    "neg_F1 = []\n",
    "neu_pre = []\n",
    "neu_re = []\n",
    "neu_F1 = []\n",
    "pos_pre = []\n",
    "pos_re = []\n",
    "pos_F1 = []\n",
    "  \n",
    "for train_index, test_index in skf.split(X_train_tfidf, Y_train):\n",
    "    x_train_fold, x_test_fold = x_scaled[train_index], x_scaled[test_index]\n",
    "    y_train_fold, y_test_fold = Y_train[train_index], Y_train[test_index]\n",
    "    #LR\n",
    "    LRmodel.fit(x_train_fold, y_train_fold)\n",
    "    pred = LRmodel.predict(x_test_fold)\n",
    "    lst_accu_stratified.append(LRmodel.score(x_test_fold, y_test_fold))\n",
    "\n",
    "    matrix = classification_report(y_test_fold, pred, output_dict = True)\n",
    "    neg_pre.append(matrix['negative']['precision'])\n",
    "    neg_re.append(matrix['negative']['recall'])\n",
    "    neg_F1.append(matrix['negative']['f1-score'])\n",
    "    neu_pre.append(matrix['neutral']['precision'])\n",
    "    neu_re.append(matrix['neutral']['recall'])\n",
    "    neu_F1.append(matrix['neutral']['f1-score'])\n",
    "    pos_pre.append(matrix['positive']['precision'])\n",
    "    pos_re.append(matrix['positive']['recall'])\n",
    "    pos_F1.append(matrix['positive']['f1-score'])\n",
    "\n",
    "    \n",
    "print('List of possible accuracy:', lst_accu_stratified)\n",
    "print('\\nMaximum Accuracy That can be obtained from this model is:',\n",
    "      max(lst_accu_stratified)*100, '%')\n",
    "print('\\nMinimum Accuracy:',\n",
    "      min(lst_accu_stratified)*100, '%')\n",
    "print('\\nOverall Accuracy:',\n",
    "      np.mean(lst_accu_stratified)*100, '%')\n",
    "print('\\nOverall Neg Pre:',\n",
    "      np.mean(neg_pre)*100, '%')\n",
    "print('\\nOverall Neg Rec:',\n",
    "      np.mean(neg_re)*100, '%')\n",
    "print('\\nOverall Neg F1:',\n",
    "      np.mean(neg_F1)*100, '%')\n",
    "print('\\nOverall Neu Pre:',\n",
    "      np.mean(neu_pre)*100, '%')\n",
    "print('\\nOverall Neu Rec:',\n",
    "      np.mean(neu_re)*100, '%')\n",
    "print('\\nOverall Neg F1:',\n",
    "      np.mean(neu_F1)*100, '%')\n",
    "print('\\nOverall Pos Pre:',\n",
    "      np.mean(pos_pre)*100, '%')\n",
    "print('\\nOverall pos Rec:',\n",
    "      np.mean(pos_re)*100, '%')\n",
    "print('\\nOverall pos F1:',\n",
    "      np.mean(pos_F1)*100, '%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "skf = KFold(n_splits=10)\n",
    "lst_accu_stratified = []\n",
    "neg_pre = []\n",
    "neg_re = []\n",
    "neg_F1 = []\n",
    "neu_pre = []\n",
    "neu_re = []\n",
    "neu_F1 = []\n",
    "pos_pre = []\n",
    "pos_re = []\n",
    "pos_F1 = []\n",
    "  \n",
    "for train_index, test_index in skf.split(X_train_tfidf, Y_train):\n",
    "    x_train_fold, x_test_fold = x_scaled[train_index], x_scaled[test_index]\n",
    "    y_train_fold, y_test_fold = Y_train[train_index], Y_train[test_index]\n",
    "\n",
    "    #SVM\n",
    "    SVCmodel.fit(x_train_fold, y_train_fold)\n",
    "    pred = SVCmodel.predict(x_test_fold)\n",
    "    lst_accu_stratified.append(SVCmodel.score(x_test_fold, y_test_fold))\n",
    "\n",
    "    matrix = classification_report(y_test_fold, pred, output_dict = True)\n",
    "    neg_pre.append(matrix['negative']['precision'])\n",
    "    neg_re.append(matrix['negative']['recall'])\n",
    "    neg_F1.append(matrix['negative']['f1-score'])\n",
    "    neu_pre.append(matrix['neutral']['precision'])\n",
    "    neu_re.append(matrix['neutral']['recall'])\n",
    "    neu_F1.append(matrix['neutral']['f1-score'])\n",
    "    pos_pre.append(matrix['positive']['precision'])\n",
    "    pos_re.append(matrix['positive']['recall'])\n",
    "    pos_F1.append(matrix['positive']['f1-score'])\n",
    "    \n",
    "    \n",
    "print('List of possible accuracy:', lst_accu_stratified)\n",
    "print('\\nMaximum Accuracy That can be obtained from this model is:',\n",
    "      max(lst_accu_stratified)*100, '%')\n",
    "print('\\nMinimum Accuracy:',\n",
    "      min(lst_accu_stratified)*100, '%')\n",
    "print('\\nOverall Accuracy:',\n",
    "      np.mean(lst_accu_stratified)*100, '%')\n",
    "print('\\nOverall Neg Pre:',\n",
    "      np.mean(neg_pre)*100, '%')\n",
    "print('\\nOverall Neg Rec:',\n",
    "      np.mean(neg_re)*100, '%')\n",
    "print('\\nOverall Neg F1:',\n",
    "      np.mean(neg_F1)*100, '%')\n",
    "print('\\nOverall Neu Pre:',\n",
    "      np.mean(neu_pre)*100, '%')\n",
    "print('\\nOverall Neu Rec:',\n",
    "      np.mean(neu_re)*100, '%')\n",
    "print('\\nOverall Neg F1:',\n",
    "      np.mean(neu_F1)*100, '%')\n",
    "print('\\nOverall Pos Pre:',\n",
    "      np.mean(pos_pre)*100, '%')\n",
    "print('\\nOverall pos Rec:',\n",
    "      np.mean(pos_re)*100, '%')\n",
    "print('\\nOverall pos F1:',\n",
    "      np.mean(pos_F1)*100, '%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "List of possible accuracy: [0.6102705181109582, 0.6198991288399817, 0.6211009174311927, 0.6064220183486239, 0.6261467889908257, 0.6137614678899083, 0.634862385321101, 0.6192660550458715, 0.6091743119266055, 0.5972477064220183]\n",
      "\n",
      "Maximum Accuracy That can be obtained from this model is: 63.48623853211009 %\n",
      "\n",
      "Minimum Accuracy: 59.72477064220183 %\n",
      "\n",
      "Overall Accuracy: 61.58151298327087 %\n",
      "\n",
      "Overall Neg Pre: 51.13731563558201 %\n",
      "\n",
      "Overall Neg Rec: 30.95448221893749 %\n",
      "\n",
      "Overall Neg F1: 38.524873277949304 %\n",
      "\n",
      "Overall Neu Pre: 64.54209496280555 %\n",
      "\n",
      "Overall Neu Rec: 79.12926711999451 %\n",
      "\n",
      "Overall Neg F1: 71.0898061820406 %\n",
      "\n",
      "Overall Pos Pre: 56.107630133287834 %\n",
      "\n",
      "Overall pos Rec: 41.617771978824756 %\n",
      "\n",
      "Overall pos F1: 47.75782011017493 %\n"
     ]
    }
   ],
   "source": [
    "#SKF MNB\n",
    "scaler = preprocessing.MaxAbsScaler()\n",
    "x_scaled = scaler.fit_transform(X_train_tfidf)\n",
    "\n",
    "skf = StratifiedKFold(n_splits=10, shuffle=True, random_state=1)\n",
    "lst_accu_stratified = []\n",
    "neg_pre = []\n",
    "neg_re = []\n",
    "neg_F1 = []\n",
    "neu_pre = []\n",
    "neu_re = []\n",
    "neu_F1 = []\n",
    "pos_pre = []\n",
    "pos_re = []\n",
    "pos_F1 = []\n",
    "  \n",
    "for train_index, test_index in skf.split(X_train_tfidf, Y_train):\n",
    "    x_train_fold, x_test_fold = x_scaled[train_index], x_scaled[test_index]\n",
    "    y_train_fold, y_test_fold = Y_train[train_index], Y_train[test_index]\n",
    "\n",
    "    MNBmodel.fit(x_train_fold, y_train_fold)\n",
    "    pred = MNBmodel.predict(x_test_fold)\n",
    "    lst_accu_stratified.append(MNBmodel.score(x_test_fold, y_test_fold))\n",
    "\n",
    "    matrix = classification_report(y_test_fold, pred, output_dict = True)\n",
    "    neg_pre.append(matrix['negative']['precision'])\n",
    "    neg_re.append(matrix['negative']['recall'])\n",
    "    neg_F1.append(matrix['negative']['f1-score'])\n",
    "    neu_pre.append(matrix['neutral']['precision'])\n",
    "    neu_re.append(matrix['neutral']['recall'])\n",
    "    neu_F1.append(matrix['neutral']['f1-score'])\n",
    "    pos_pre.append(matrix['positive']['precision'])\n",
    "    pos_re.append(matrix['positive']['recall'])\n",
    "    pos_F1.append(matrix['positive']['f1-score'])\n",
    "\n",
    "    \n",
    "print('List of possible accuracy:', lst_accu_stratified)\n",
    "print('\\nMaximum Accuracy That can be obtained from this model is:',\n",
    "      max(lst_accu_stratified)*100, '%')\n",
    "print('\\nMinimum Accuracy:',\n",
    "      min(lst_accu_stratified)*100, '%')\n",
    "print('\\nOverall Accuracy:',\n",
    "      np.mean(lst_accu_stratified)*100, '%')\n",
    "print('\\nOverall Neg Pre:',\n",
    "      np.mean(neg_pre)*100, '%')\n",
    "print('\\nOverall Neg Rec:',\n",
    "      np.mean(neg_re)*100, '%')\n",
    "print('\\nOverall Neg F1:',\n",
    "      np.mean(neg_F1)*100, '%')\n",
    "print('\\nOverall Neu Pre:',\n",
    "      np.mean(neu_pre)*100, '%')\n",
    "print('\\nOverall Neu Rec:',\n",
    "      np.mean(neu_re)*100, '%')\n",
    "print('\\nOverall Neg F1:',\n",
    "      np.mean(neu_F1)*100, '%')\n",
    "print('\\nOverall Pos Pre:',\n",
    "      np.mean(pos_pre)*100, '%')\n",
    "print('\\nOverall pos Rec:',\n",
    "      np.mean(pos_re)*100, '%')\n",
    "print('\\nOverall pos F1:',\n",
    "      np.mean(pos_F1)*100, '%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "List of possible accuracy: [0.6616231086657497, 0.6629986244841816, 0.6614678899082569, 0.6353211009174312, 0.6688073394495413, 0.6688073394495413, 0.6697247706422018, 0.6490825688073395, 0.6770642201834862, 0.6490825688073395]\n",
      "\n",
      "Maximum Accuracy That can be obtained from this model is: 67.70642201834862 %\n",
      "\n",
      "Minimum Accuracy: 63.53211009174312 %\n",
      "\n",
      "Overall Accuracy: 66.03979531315069 %\n",
      "\n",
      "Overall Neg Pre: 58.74386489611221 %\n",
      "\n",
      "Overall Neg Rec: 33.728733733298554 %\n",
      "\n",
      "Overall Neg F1: 42.829001218024324 %\n",
      "\n",
      "Overall Neu Pre: 67.36288595808695 %\n",
      "\n",
      "Overall Neu Rec: 83.95593478573078 %\n",
      "\n",
      "Overall Neg F1: 74.74685501982763 %\n",
      "\n",
      "Overall Pos Pre: 64.73404754976791 %\n",
      "\n",
      "Overall pos Rec: 46.37078414983045 %\n",
      "\n",
      "Overall pos F1: 54.01813431143625 %\n"
     ]
    }
   ],
   "source": [
    "#SKF Logistic Regression\n",
    "skf = StratifiedKFold(n_splits=10, shuffle=True, random_state=1)\n",
    "lst_accu_stratified = []\n",
    "neg_pre = []\n",
    "neg_re = []\n",
    "neg_F1 = []\n",
    "neu_pre = []\n",
    "neu_re = []\n",
    "neu_F1 = []\n",
    "pos_pre = []\n",
    "pos_re = []\n",
    "pos_F1 = []\n",
    "  \n",
    "for train_index, test_index in skf.split(X_train_tfidf, Y_train):\n",
    "    x_train_fold, x_test_fold = x_scaled[train_index], x_scaled[test_index]\n",
    "    y_train_fold, y_test_fold = Y_train[train_index], Y_train[test_index]\n",
    "    #LR\n",
    "    LRmodel.fit(x_train_fold, y_train_fold)\n",
    "    pred = LRmodel.predict(x_test_fold)\n",
    "    lst_accu_stratified.append(LRmodel.score(x_test_fold, y_test_fold))\n",
    "\n",
    "    matrix = classification_report(y_test_fold, pred, output_dict = True)\n",
    "    neg_pre.append(matrix['negative']['precision'])\n",
    "    neg_re.append(matrix['negative']['recall'])\n",
    "    neg_F1.append(matrix['negative']['f1-score'])\n",
    "    neu_pre.append(matrix['neutral']['precision'])\n",
    "    neu_re.append(matrix['neutral']['recall'])\n",
    "    neu_F1.append(matrix['neutral']['f1-score'])\n",
    "    pos_pre.append(matrix['positive']['precision'])\n",
    "    pos_re.append(matrix['positive']['recall'])\n",
    "    pos_F1.append(matrix['positive']['f1-score'])\n",
    "\n",
    "    \n",
    "print('List of possible accuracy:', lst_accu_stratified)\n",
    "print('\\nMaximum Accuracy That can be obtained from this model is:',\n",
    "      max(lst_accu_stratified)*100, '%')\n",
    "print('\\nMinimum Accuracy:',\n",
    "      min(lst_accu_stratified)*100, '%')\n",
    "print('\\nOverall Accuracy:',\n",
    "      np.mean(lst_accu_stratified)*100, '%')\n",
    "print('\\nOverall Neg Pre:',\n",
    "      np.mean(neg_pre)*100, '%')\n",
    "print('\\nOverall Neg Rec:',\n",
    "      np.mean(neg_re)*100, '%')\n",
    "print('\\nOverall Neg F1:',\n",
    "      np.mean(neg_F1)*100, '%')\n",
    "print('\\nOverall Neu Pre:',\n",
    "      np.mean(neu_pre)*100, '%')\n",
    "print('\\nOverall Neu Rec:',\n",
    "      np.mean(neu_re)*100, '%')\n",
    "print('\\nOverall Neg F1:',\n",
    "      np.mean(neu_F1)*100, '%')\n",
    "print('\\nOverall Pos Pre:',\n",
    "      np.mean(pos_pre)*100, '%')\n",
    "print('\\nOverall pos Rec:',\n",
    "      np.mean(pos_re)*100, '%')\n",
    "print('\\nOverall pos F1:',\n",
    "      np.mean(pos_F1)*100, '%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "List of possible accuracy: [0.6414488766620816, 0.6529115084823476, 0.6449541284403669, 0.6233944954128441, 0.6458715596330276, 0.6458715596330276, 0.6486238532110091, 0.6311926605504588, 0.6591743119266055, 0.6307339449541285]\n",
      "\n",
      "Maximum Accuracy That can be obtained from this model is: 65.91743119266054 %\n",
      "\n",
      "Minimum Accuracy: 62.33944954128441 %\n",
      "\n",
      "Overall Accuracy: 64.24176898905897 %\n",
      "\n",
      "Overall Neg Pre: 51.35766473060147 %\n",
      "\n",
      "Overall Neg Rec: 40.94238182187057 %\n",
      "\n",
      "Overall Neg F1: 45.54935442364321 %\n",
      "\n",
      "Overall Neu Pre: 68.0982563026029 %\n",
      "\n",
      "Overall Neu Rec: 77.09915141524456 %\n",
      "\n",
      "Overall Neg F1: 72.3147080108876 %\n",
      "\n",
      "Overall Pos Pre: 60.51166593135381 %\n",
      "\n",
      "Overall pos Rec: 50.20247633415561 %\n",
      "\n",
      "Overall pos F1: 54.849073586321474 %\n"
     ]
    }
   ],
   "source": [
    "#SKF SVM\n",
    "skf = StratifiedKFold(n_splits=10, shuffle=True, random_state=1)\n",
    "lst_accu_stratified = []\n",
    "neg_pre = []\n",
    "neg_re = []\n",
    "neg_F1 = []\n",
    "neu_pre = []\n",
    "neu_re = []\n",
    "neu_F1 = []\n",
    "pos_pre = []\n",
    "pos_re = []\n",
    "pos_F1 = []\n",
    "  \n",
    "for train_index, test_index in skf.split(X_train_tfidf, Y_train):\n",
    "    x_train_fold, x_test_fold = x_scaled[train_index], x_scaled[test_index]\n",
    "    y_train_fold, y_test_fold = Y_train[train_index], Y_train[test_index]\n",
    "\n",
    "    #SVM\n",
    "    SVCmodel.fit(x_train_fold, y_train_fold)\n",
    "    pred = SVCmodel.predict(x_test_fold)\n",
    "    lst_accu_stratified.append(SVCmodel.score(x_test_fold, y_test_fold))\n",
    "\n",
    "    matrix = classification_report(y_test_fold, pred, output_dict = True)\n",
    "    neg_pre.append(matrix['negative']['precision'])\n",
    "    neg_re.append(matrix['negative']['recall'])\n",
    "    neg_F1.append(matrix['negative']['f1-score'])\n",
    "    neu_pre.append(matrix['neutral']['precision'])\n",
    "    neu_re.append(matrix['neutral']['recall'])\n",
    "    neu_F1.append(matrix['neutral']['f1-score'])\n",
    "    pos_pre.append(matrix['positive']['precision'])\n",
    "    pos_re.append(matrix['positive']['recall'])\n",
    "    pos_F1.append(matrix['positive']['f1-score'])\n",
    "\n",
    "    \n",
    "print('List of possible accuracy:', lst_accu_stratified)\n",
    "print('\\nMaximum Accuracy That can be obtained from this model is:',\n",
    "      max(lst_accu_stratified)*100, '%')\n",
    "print('\\nMinimum Accuracy:',\n",
    "      min(lst_accu_stratified)*100, '%')\n",
    "print('\\nOverall Accuracy:',\n",
    "      np.mean(lst_accu_stratified)*100, '%')\n",
    "print('\\nOverall Neg Pre:',\n",
    "      np.mean(neg_pre)*100, '%')\n",
    "print('\\nOverall Neg Rec:',\n",
    "      np.mean(neg_re)*100, '%')\n",
    "print('\\nOverall Neg F1:',\n",
    "      np.mean(neg_F1)*100, '%')\n",
    "print('\\nOverall Neu Pre:',\n",
    "      np.mean(neu_pre)*100, '%')\n",
    "print('\\nOverall Neu Rec:',\n",
    "      np.mean(neu_re)*100, '%')\n",
    "print('\\nOverall Neg F1:',\n",
    "      np.mean(neu_F1)*100, '%')\n",
    "print('\\nOverall Pos Pre:',\n",
    "      np.mean(pos_pre)*100, '%')\n",
    "print('\\nOverall pos Rec:',\n",
    "      np.mean(pos_re)*100, '%')\n",
    "print('\\nOverall pos F1:',\n",
    "      np.mean(pos_F1)*100, '%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = SVCmodel.predict(X_test_tfidf)\n",
    "df_SVC_clean = pd.DataFrame(columns = [\"id\", \"sentiment\"])\n",
    "for i in range(len(X_test_ID)):\n",
    "    new_row = {\"id\": X_test_ID[i], \"sentiment\": pred[i]}\n",
    "    df_SVC_clean = df_SVC_clean.append(new_row, ignore_index = True)\n",
    "df_SVC_clean.to_csv('prediction_SVC_clean.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. With oversampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv(\"Train.csv\", sep=',', encoding=\"utf-8\")\n",
    "test_data = pd.read_csv(\"Test.csv\", sep=',', encoding=\"utf-8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "neutral = train_data[train_data['sentiment'] == 'neutral']\n",
    "positive = train_data[train_data['sentiment'] == 'positive']\n",
    "negative = train_data[train_data['sentiment'] == 'negative']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_pos = positive.append(positive)\n",
    "new_neg = negative.append(negative.append(negative))\n",
    "train_data = neutral.append(new_pos.append(new_neg))\n",
    "train_data = train_data.sample(frac = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_raw = [x[0] for x in train_data[['text']].values]\n",
    "Y_train = [x[0] for x in train_data[['sentiment']].values]\n",
    "\n",
    "X_test_raw = [x[0] for x in test_data[['text']].values]\n",
    "X_test_ID = [x[0] for x in test_data[['id']].values]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train = np.array(Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_vectorizer = TfidfVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "english_stopwords = stopwords.words('english') + [\"'d\"]\n",
    "negated_token = 'negation'\n",
    "negation_stopwords = ['not', 'ain', \"should've\", \"could've\", 'shouldve', 'couldve', 'aren',\"aren't\",\n",
    " 'couldn',\n",
    " \"couldn't\",\n",
    " 'didn',\n",
    " \"didn't\",\n",
    " 'doesn',\n",
    " \"doesn't\",\n",
    " 'hadn',\n",
    " \"hadn't\",\n",
    " 'hasn',\n",
    " \"hasn't\",\n",
    " 'haven',\n",
    " \"haven't\",\n",
    " 'isn',\n",
    " \"isn't\",\n",
    " 'mightn',\n",
    " \"mightn't\",\n",
    " 'mustn',\n",
    " \"mustn't\",\n",
    " 'needn',\n",
    " \"needn't\",\n",
    " 'shan',\n",
    " \"shan't\",\n",
    " 'shouldn',\n",
    " \"shouldn't\",\n",
    " 'wasn',\n",
    " \"wasn't\",\n",
    " 'weren',\n",
    " \"weren't\",\n",
    " 'won',\n",
    " \"won't\",\n",
    " 'wouldn',\n",
    " \"wouldn't\", \n",
    " 'don',\n",
    " \"don't\"]\n",
    "neutral_stopwords = [word for word in english_stopwords if word not in negation_stopwords]\n",
    "no_apostrophe_stopwords = [re.sub(r'\\'', '', str(word)) for word in negation_stopwords]\n",
    "contrast_language = ['but', 'yet', 'however', 'despite', 'although', 'though', 'contrast']\n",
    "contrast_token = 'contrast'\n",
    "\n",
    "def process_tweet(tweet):\n",
    "    stemmer = PorterStemmer()\n",
    "    \n",
    "    tweet = tweet.lower() # lowercase everything\n",
    "    \n",
    "    #removing hyperlinks\n",
    "    tweet = re.sub(r'(http|https)?:\\/\\/(\\S+)', '', str(tweet))\n",
    "    \n",
    "    tweet = re.sub(r'#', '', str(tweet)) \n",
    "    #remove hashtags\n",
    "    \n",
    "    #removing usernames\n",
    "    tweet = re.sub(r'/(?<!\\w)@[\\w+]{1,15}\\b/', '', str(tweet))\n",
    "    \n",
    "    #removing numbers\n",
    "    tweet = re.sub(r'[0-9]+', '', str(tweet))\n",
    "    \n",
    "    #substitute common abbreviation\n",
    "    tweet = re.sub(r'wtf', \"what the fuck\", str(tweet))\n",
    "    tweet = re.sub(r'wth', \"what the hell\", str(tweet))\n",
    "    tweet = re.sub(r'rofl', \"rolling on floor laughing\", str(tweet))\n",
    "    tweet = re.sub(r'stfu', \"shut the fuck up\", str(tweet))\n",
    "    tweet = re.sub(r'btw', \"by the way\", str(tweet))\n",
    "    tweet = re.sub(r'lol', \"laugh out loud\", str(tweet))\n",
    "    tweet = re.sub(r'hmu', \"hit me up\", str(tweet))\n",
    "    tweet = re.sub(r'imo', \"in my opinion\", str(tweet))\n",
    "    tweet = re.sub(r'idk', \"I don't know\", str(tweet))\n",
    "    tweet = re.sub(r'idc', \"I don't care\", str(tweet))\n",
    "    tweet = re.sub(r'icymi', \"in case you missed it\", str(tweet))\n",
    "    tweet = re.sub(r'lmk', \"let me know\", str(tweet))\n",
    "    tweet = re.sub(r'nvm', \"nevermind\", str(tweet))\n",
    "    tweet = re.sub(r'tbh', \"to be honest\", str(tweet))\n",
    "    tweet = re.sub(r'tbf', \"to be frank\", str(tweet))\n",
    "    tweet = re.sub(r'lmao', \"laughing my ass off\", str(tweet))\n",
    "    tweet = re.sub(r'lmfao', \"laughing my fucking ass off\", str(tweet))\n",
    "    tweet = re.sub(r'smh', \"shaking my head\", str(tweet))\n",
    "    \n",
    "    #remove repeating characters\n",
    "    tweet = re.sub(r'(.)1+', r'1', str(tweet))\n",
    "    \n",
    "    #remove non-English characters\n",
    "    tweet = re.sub(\"[^a-zA-Z0-9\\s]+\", \" \",str(tweet))\n",
    "        \n",
    "#     tweet_tokenizer = TweetTokenizer(preserve_case=False, strip_handles=True,\n",
    "#                                reduce_len=True)\n",
    "    \n",
    "#     tokens = tweet_tokenizer.tokenize(tweet)\n",
    "    tokens = word_tokenize(tweet)\n",
    "    processed_tweet = []\n",
    "    \n",
    "    for token in tokens:\n",
    "        if len(token) <= 2:\n",
    "            continue\n",
    "        if token in negation_stopwords or token in no_apostrophe_stopwords or token in contrast_language:\n",
    "            continue\n",
    "        elif token in ['like', 'tomorrow']:\n",
    "            continue\n",
    "        elif (token not in neutral_stopwords and  # remove stopwords\n",
    "                token not in string.punctuation):  # remove punctuation\n",
    "            stemmed_token = stemmer.stem(token)  # stemming word\n",
    "            processed_tweet.append(stemmed_token)\n",
    "    return \" \".join(processed_tweet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_processed = [process_tweet(tweet) for tweet in X_train_raw]\n",
    "X_test_processed = [process_tweet(tweet) for tweet in X_test_raw]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_tfidf = tfidf_vectorizer.fit_transform(X_train_processed)\n",
    "\n",
    "#Use the feature set (vocabulary) from Train to vectorise the Test dataset \n",
    "X_test_tfidf = tfidf_vectorizer.transform(X_test_processed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'BNBmodel' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-34-b12c1d5d9445>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0mMNBmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train_fold\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train_fold\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m     \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBNBmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test_fold\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m     \u001b[0mlst_accu_stratified\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBNBmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test_fold\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test_fold\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'BNBmodel' is not defined"
     ]
    }
   ],
   "source": [
    "#K-fold MNB\n",
    "scaler = preprocessing.MaxAbsScaler()\n",
    "x_scaled = scaler.fit_transform(X_train_tfidf)\n",
    "\n",
    "skf = KFold(n_splits=10)\n",
    "lst_accu_stratified = []\n",
    "neg_pre = []\n",
    "neg_re = []\n",
    "neg_F1 = []\n",
    "neu_pre = []\n",
    "neu_re = []\n",
    "neu_F1 = []\n",
    "pos_pre = []\n",
    "pos_re = []\n",
    "pos_F1 = []\n",
    "  \n",
    "for train_index, test_index in skf.split(X_train_tfidf, Y_train):\n",
    "    x_train_fold, x_test_fold = x_scaled[train_index], x_scaled[test_index]\n",
    "    y_train_fold, y_test_fold = Y_train[train_index], Y_train[test_index]\n",
    "\n",
    "    MNBmodel.fit(x_train_fold, y_train_fold)\n",
    "    pred = BNBmodel.predict(x_test_fold)\n",
    "    lst_accu_stratified.append(BNBmodel.score(x_test_fold, y_test_fold))\n",
    "\n",
    "    matrix = classification_report(y_test_fold, pred, output_dict = True)\n",
    "    neg_pre.append(matrix['negative']['precision'])\n",
    "    neg_re.append(matrix['negative']['recall'])\n",
    "    neg_F1.append(matrix['negative']['f1-score'])\n",
    "    neu_pre.append(matrix['neutral']['precision'])\n",
    "    neu_re.append(matrix['neutral']['recall'])\n",
    "    neu_F1.append(matrix['neutral']['f1-score'])\n",
    "    pos_pre.append(matrix['positive']['precision'])\n",
    "    pos_re.append(matrix['positive']['recall'])\n",
    "    pos_F1.append(matrix['positive']['f1-score'])\n",
    "\n",
    "    \n",
    "print('List of possible accuracy:', lst_accu_stratified)\n",
    "print('\\nMaximum Accuracy That can be obtained from this model is:',\n",
    "      max(lst_accu_stratified)*100, '%')\n",
    "print('\\nMinimum Accuracy:',\n",
    "      min(lst_accu_stratified)*100, '%')\n",
    "print('\\nOverall Accuracy:',\n",
    "      np.mean(lst_accu_stratified)*100, '%')\n",
    "print('\\nOverall Neg Pre:',\n",
    "      np.mean(neg_pre)*100, '%')\n",
    "print('\\nOverall Neg Rec:',\n",
    "      np.mean(neg_re)*100, '%')\n",
    "print('\\nOverall Neg F1:',\n",
    "      np.mean(neg_F1)*100, '%')\n",
    "print('\\nOverall Neu Pre:',\n",
    "      np.mean(neu_pre)*100, '%')\n",
    "print('\\nOverall Neu Rec:',\n",
    "      np.mean(neu_re)*100, '%')\n",
    "print('\\nOverall Neg F1:',\n",
    "      np.mean(neu_F1)*100, '%')\n",
    "print('\\nOverall Pos Pre:',\n",
    "      np.mean(pos_pre)*100, '%')\n",
    "print('\\nOverall pos Rec:',\n",
    "      np.mean(pos_re)*100, '%')\n",
    "print('\\nOverall pos F1:',\n",
    "      np.mean(pos_F1)*100, '%')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#K-fold Logistic Regression\n",
    "skf = KFold(n_splits=10)\n",
    "lst_accu_stratified = []\n",
    "neg_pre = []\n",
    "neg_re = []\n",
    "neg_F1 = []\n",
    "neu_pre = []\n",
    "neu_re = []\n",
    "neu_F1 = []\n",
    "pos_pre = []\n",
    "pos_re = []\n",
    "pos_F1 = []\n",
    "  \n",
    "for train_index, test_index in skf.split(X_train_tfidf, Y_train):\n",
    "    x_train_fold, x_test_fold = x_scaled[train_index], x_scaled[test_index]\n",
    "    y_train_fold, y_test_fold = Y_train[train_index], Y_train[test_index]\n",
    "    #LR\n",
    "    LRmodel.fit(x_train_fold, y_train_fold)\n",
    "    pred = LRmodel.predict(x_test_fold)\n",
    "    lst_accu_stratified.append(LRmodel.score(x_test_fold, y_test_fold))\n",
    "\n",
    "    matrix = classification_report(y_test_fold, pred, output_dict = True)\n",
    "    neg_pre.append(matrix['negative']['precision'])\n",
    "    neg_re.append(matrix['negative']['recall'])\n",
    "    neg_F1.append(matrix['negative']['f1-score'])\n",
    "    neu_pre.append(matrix['neutral']['precision'])\n",
    "    neu_re.append(matrix['neutral']['recall'])\n",
    "    neu_F1.append(matrix['neutral']['f1-score'])\n",
    "    pos_pre.append(matrix['positive']['precision'])\n",
    "    pos_re.append(matrix['positive']['recall'])\n",
    "    pos_F1.append(matrix['positive']['f1-score'])\n",
    "\n",
    "    \n",
    "print('List of possible accuracy:', lst_accu_stratified)\n",
    "print('\\nMaximum Accuracy That can be obtained from this model is:',\n",
    "      max(lst_accu_stratified)*100, '%')\n",
    "print('\\nMinimum Accuracy:',\n",
    "      min(lst_accu_stratified)*100, '%')\n",
    "print('\\nOverall Accuracy:',\n",
    "      np.mean(lst_accu_stratified)*100, '%')\n",
    "print('\\nOverall Neg Pre:',\n",
    "      np.mean(neg_pre)*100, '%')\n",
    "print('\\nOverall Neg Rec:',\n",
    "      np.mean(neg_re)*100, '%')\n",
    "print('\\nOverall Neg F1:',\n",
    "      np.mean(neg_F1)*100, '%')\n",
    "print('\\nOverall Neu Pre:',\n",
    "      np.mean(neu_pre)*100, '%')\n",
    "print('\\nOverall Neu Rec:',\n",
    "      np.mean(neu_re)*100, '%')\n",
    "print('\\nOverall Neg F1:',\n",
    "      np.mean(neu_F1)*100, '%')\n",
    "print('\\nOverall Pos Pre:',\n",
    "      np.mean(pos_pre)*100, '%')\n",
    "print('\\nOverall pos Rec:',\n",
    "      np.mean(pos_re)*100, '%')\n",
    "print('\\nOverall pos F1:',\n",
    "      np.mean(pos_F1)*100, '%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#K-fold SVM\n",
    "skf = KFold(n_splits=10)\n",
    "lst_accu_stratified = []\n",
    "neg_pre = []\n",
    "neg_re = []\n",
    "neg_F1 = []\n",
    "neu_pre = []\n",
    "neu_re = []\n",
    "neu_F1 = []\n",
    "pos_pre = []\n",
    "pos_re = []\n",
    "pos_F1 = []\n",
    "  \n",
    "for train_index, test_index in skf.split(X_train_tfidf, Y_train):\n",
    "    x_train_fold, x_test_fold = x_scaled[train_index], x_scaled[test_index]\n",
    "    y_train_fold, y_test_fold = Y_train[train_index], Y_train[test_index]\n",
    "\n",
    "    #SVM\n",
    "    SVCmodel.fit(x_train_fold, y_train_fold)\n",
    "    pred = SVCmodel.predict(x_test_fold)\n",
    "    lst_accu_stratified.append(SVCmodel.score(x_test_fold, y_test_fold))\n",
    "\n",
    "    matrix = classification_report(y_test_fold, pred, output_dict = True)\n",
    "    neg_pre.append(matrix['negative']['precision'])\n",
    "    neg_re.append(matrix['negative']['recall'])\n",
    "    neg_F1.append(matrix['negative']['f1-score'])\n",
    "    neu_pre.append(matrix['neutral']['precision'])\n",
    "    neu_re.append(matrix['neutral']['recall'])\n",
    "    neu_F1.append(matrix['neutral']['f1-score'])\n",
    "    pos_pre.append(matrix['positive']['precision'])\n",
    "    pos_re.append(matrix['positive']['recall'])\n",
    "    pos_F1.append(matrix['positive']['f1-score'])\n",
    "\n",
    "    \n",
    "print('List of possible accuracy:', lst_accu_stratified)\n",
    "print('\\nMaximum Accuracy That can be obtained from this model is:',\n",
    "      max(lst_accu_stratified)*100, '%')\n",
    "print('\\nMinimum Accuracy:',\n",
    "      min(lst_accu_stratified)*100, '%')\n",
    "print('\\nOverall Accuracy:',\n",
    "      np.mean(lst_accu_stratified)*100, '%')\n",
    "print('\\nOverall Neg Pre:',\n",
    "      np.mean(neg_pre)*100, '%')\n",
    "print('\\nOverall Neg Rec:',\n",
    "      np.mean(neg_re)*100, '%')\n",
    "print('\\nOverall Neg F1:',\n",
    "      np.mean(neg_F1)*100, '%')\n",
    "print('\\nOverall Neu Pre:',\n",
    "      np.mean(neu_pre)*100, '%')\n",
    "print('\\nOverall Neu Rec:',\n",
    "      np.mean(neu_re)*100, '%')\n",
    "print('\\nOverall Neg F1:',\n",
    "      np.mean(neu_F1)*100, '%')\n",
    "print('\\nOverall Pos Pre:',\n",
    "      np.mean(pos_pre)*100, '%')\n",
    "print('\\nOverall pos Rec:',\n",
    "      np.mean(pos_re)*100, '%')\n",
    "print('\\nOverall pos F1:',\n",
    "      np.mean(pos_F1)*100, '%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SKF MNB\n",
    "scaler = preprocessing.MaxAbsScaler()\n",
    "x_scaled = scaler.fit_transform(X_train_tfidf)\n",
    "\n",
    "skf = StratifiedKFold(n_splits=10, shuffle=True, random_state=1)\n",
    "lst_accu_stratified = []\n",
    "neg_pre = []\n",
    "neg_re = []\n",
    "neg_F1 = []\n",
    "neu_pre = []\n",
    "neu_re = []\n",
    "neu_F1 = []\n",
    "pos_pre = []\n",
    "pos_re = []\n",
    "pos_F1 = []\n",
    "  \n",
    "for train_index, test_index in skf.split(X_train_tfidf, Y_train):\n",
    "    x_train_fold, x_test_fold = x_scaled[train_index], x_scaled[test_index]\n",
    "    y_train_fold, y_test_fold = Y_train[train_index], Y_train[test_index]\n",
    "\n",
    "    MNBmodel.fit(x_train_fold, y_train_fold)\n",
    "    pred = BNBmodel.predict(x_test_fold)\n",
    "    lst_accu_stratified.append(BNBmodel.score(x_test_fold, y_test_fold))\n",
    "\n",
    "    matrix = classification_report(y_test_fold, pred, output_dict = True)\n",
    "    neg_pre.append(matrix['negative']['precision'])\n",
    "    neg_re.append(matrix['negative']['recall'])\n",
    "    neg_F1.append(matrix['negative']['f1-score'])\n",
    "    neu_pre.append(matrix['neutral']['precision'])\n",
    "    neu_re.append(matrix['neutral']['recall'])\n",
    "    neu_F1.append(matrix['neutral']['f1-score'])\n",
    "    pos_pre.append(matrix['positive']['precision'])\n",
    "    pos_re.append(matrix['positive']['recall'])\n",
    "    pos_F1.append(matrix['positive']['f1-score'])\n",
    "\n",
    "    \n",
    "print('List of possible accuracy:', lst_accu_stratified)\n",
    "print('\\nMaximum Accuracy That can be obtained from this model is:',\n",
    "      max(lst_accu_stratified)*100, '%')\n",
    "print('\\nMinimum Accuracy:',\n",
    "      min(lst_accu_stratified)*100, '%')\n",
    "print('\\nOverall Accuracy:',\n",
    "      np.mean(lst_accu_stratified)*100, '%')\n",
    "print('\\nOverall Neg Pre:',\n",
    "      np.mean(neg_pre)*100, '%')\n",
    "print('\\nOverall Neg Rec:',\n",
    "      np.mean(neg_re)*100, '%')\n",
    "print('\\nOverall Neg F1:',\n",
    "      np.mean(neg_F1)*100, '%')\n",
    "print('\\nOverall Neu Pre:',\n",
    "      np.mean(neu_pre)*100, '%')\n",
    "print('\\nOverall Neu Rec:',\n",
    "      np.mean(neu_re)*100, '%')\n",
    "print('\\nOverall Neg F1:',\n",
    "      np.mean(neu_F1)*100, '%')\n",
    "print('\\nOverall Pos Pre:',\n",
    "      np.mean(pos_pre)*100, '%')\n",
    "print('\\nOverall pos Rec:',\n",
    "      np.mean(pos_re)*100, '%')\n",
    "print('\\nOverall pos F1:',\n",
    "      np.mean(pos_F1)*100, '%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SKF Logistic Regression\n",
    "skf = StratifiedKFold(n_splits=10, shuffle=True, random_state=1)\n",
    "lst_accu_stratified = []\n",
    "neg_pre = []\n",
    "neg_re = []\n",
    "neg_F1 = []\n",
    "neu_pre = []\n",
    "neu_re = []\n",
    "neu_F1 = []\n",
    "pos_pre = []\n",
    "pos_re = []\n",
    "pos_F1 = []\n",
    "  \n",
    "for train_index, test_index in skf.split(X_train_tfidf, Y_train):\n",
    "    x_train_fold, x_test_fold = x_scaled[train_index], x_scaled[test_index]\n",
    "    y_train_fold, y_test_fold = Y_train[train_index], Y_train[test_index]\n",
    "    #LR\n",
    "    LRmodel.fit(x_train_fold, y_train_fold)\n",
    "    pred = LRmodel.predict(x_test_fold)\n",
    "    lst_accu_stratified.append(LRmodel.score(x_test_fold, y_test_fold))\n",
    "\n",
    "    matrix = classification_report(y_test_fold, pred, output_dict = True)\n",
    "    neg_pre.append(matrix['negative']['precision'])\n",
    "    neg_re.append(matrix['negative']['recall'])\n",
    "    neg_F1.append(matrix['negative']['f1-score'])\n",
    "    neu_pre.append(matrix['neutral']['precision'])\n",
    "    neu_re.append(matrix['neutral']['recall'])\n",
    "    neu_F1.append(matrix['neutral']['f1-score'])\n",
    "    pos_pre.append(matrix['positive']['precision'])\n",
    "    pos_re.append(matrix['positive']['recall'])\n",
    "    pos_F1.append(matrix['positive']['f1-score'])\n",
    "\n",
    "    \n",
    "print('List of possible accuracy:', lst_accu_stratified)\n",
    "print('\\nMaximum Accuracy That can be obtained from this model is:',\n",
    "      max(lst_accu_stratified)*100, '%')\n",
    "print('\\nMinimum Accuracy:',\n",
    "      min(lst_accu_stratified)*100, '%')\n",
    "print('\\nOverall Accuracy:',\n",
    "      np.mean(lst_accu_stratified)*100, '%')\n",
    "print('\\nOverall Neg Pre:',\n",
    "      np.mean(neg_pre)*100, '%')\n",
    "print('\\nOverall Neg Rec:',\n",
    "      np.mean(neg_re)*100, '%')\n",
    "print('\\nOverall Neg F1:',\n",
    "      np.mean(neg_F1)*100, '%')\n",
    "print('\\nOverall Neu Pre:',\n",
    "      np.mean(neu_pre)*100, '%')\n",
    "print('\\nOverall Neu Rec:',\n",
    "      np.mean(neu_re)*100, '%')\n",
    "print('\\nOverall Neg F1:',\n",
    "      np.mean(neu_F1)*100, '%')\n",
    "print('\\nOverall Pos Pre:',\n",
    "      np.mean(pos_pre)*100, '%')\n",
    "print('\\nOverall pos Rec:',\n",
    "      np.mean(pos_re)*100, '%')\n",
    "print('\\nOverall pos F1:',\n",
    "      np.mean(pos_F1)*100, '%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SKF SVM\n",
    "skf = StratifiedKFold(n_splits=10, shuffle=True, random_state=1)\n",
    "lst_accu_stratified = []\n",
    "neg_pre = []\n",
    "neg_re = []\n",
    "neg_F1 = []\n",
    "neu_pre = []\n",
    "neu_re = []\n",
    "neu_F1 = []\n",
    "pos_pre = []\n",
    "pos_re = []\n",
    "pos_F1 = []\n",
    "  \n",
    "for train_index, test_index in skf.split(X_train_tfidf, Y_train):\n",
    "    x_train_fold, x_test_fold = x_scaled[train_index], x_scaled[test_index]\n",
    "    y_train_fold, y_test_fold = Y_train[train_index], Y_train[test_index]\n",
    "\n",
    "    #SVM\n",
    "    SVCmodel.fit(x_train_fold, y_train_fold)\n",
    "    pred = SVCmodel.predict(x_test_fold)\n",
    "    lst_accu_stratified.append(SVCmodel.score(x_test_fold, y_test_fold))\n",
    "\n",
    "    matrix = classification_report(y_test_fold, pred, output_dict = True)\n",
    "    neg_pre.append(matrix['negative']['precision'])\n",
    "    neg_re.append(matrix['negative']['recall'])\n",
    "    neg_F1.append(matrix['negative']['f1-score'])\n",
    "    neu_pre.append(matrix['neutral']['precision'])\n",
    "    neu_re.append(matrix['neutral']['recall'])\n",
    "    neu_F1.append(matrix['neutral']['f1-score'])\n",
    "    pos_pre.append(matrix['positive']['precision'])\n",
    "    pos_re.append(matrix['positive']['recall'])\n",
    "    pos_F1.append(matrix['positive']['f1-score'])\n",
    "\n",
    "    \n",
    "print('List of possible accuracy:', lst_accu_stratified)\n",
    "print('\\nMaximum Accuracy That can be obtained from this model is:',\n",
    "      max(lst_accu_stratified)*100, '%')\n",
    "print('\\nMinimum Accuracy:',\n",
    "      min(lst_accu_stratified)*100, '%')\n",
    "print('\\nOverall Accuracy:',\n",
    "      np.mean(lst_accu_stratified)*100, '%')\n",
    "print('\\nOverall Neg Pre:',\n",
    "      np.mean(neg_pre)*100, '%')\n",
    "print('\\nOverall Neg Rec:',\n",
    "      np.mean(neg_re)*100, '%')\n",
    "print('\\nOverall Neg F1:',\n",
    "      np.mean(neg_F1)*100, '%')\n",
    "print('\\nOverall Neu Pre:',\n",
    "      np.mean(neu_pre)*100, '%')\n",
    "print('\\nOverall Neu Rec:',\n",
    "      np.mean(neu_re)*100, '%')\n",
    "print('\\nOverall Neg F1:',\n",
    "      np.mean(neu_F1)*100, '%')\n",
    "print('\\nOverall Pos Pre:',\n",
    "      np.mean(pos_pre)*100, '%')\n",
    "print('\\nOverall pos Rec:',\n",
    "      np.mean(pos_re)*100, '%')\n",
    "print('\\nOverall pos F1:',\n",
    "      np.mean(pos_F1)*100, '%')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
